{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-18T06:54:16.574793Z",
     "start_time": "2024-03-18T06:54:16.567944Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "# create some dummy data (ANNs can fit to random noise very well!)\n",
    "#TODO: changes this dummy data to a proper dataset with fined preprocessing\n",
    "\n",
    "# dataset size: 1024; sequence length: 28; features: 10\n",
    "x_train = np.random.normal(size=(1024, 28, 10))\n",
    "# target: 0 or 1, randomly assigned\n",
    "y_train = np.random.randint(low=0, high=2, size=(1024,1))\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(1024).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "x_val = np.random.normal(size=(512, 28, 10))\n",
    "# target: 0 or 1, randomly assigned\n",
    "y_val = np.random.randint(low=0, high=2, size=(512,1))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(512).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T06:54:16.589753Z",
     "start_time": "2024-03-18T06:54:16.575498Z"
    }
   },
   "id": "9ccd706e879d29ef",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_dataset(n_samples, sequence_length, n_features):\n",
    "    x = tf.cast(np.random.randint(low=0, high=11, size=(n_samples, sequence_length, n_features)), tf.float32)\n",
    "    sums = []\n",
    "    for sample in range(n_samples):\n",
    "        value = x[sample, :, :]\n",
    "        sums.append(tf.reduce_sum(value))\n",
    "    y = tf.cast(tf.expand_dims(tf.convert_to_tensor(sums), axis=1), tf.float32)\n",
    "    return tf.data.Dataset.from_tensor_slices((x, y)).shuffle(n_samples).batch(32).prefetch(tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T06:54:16.601613Z",
     "start_time": "2024-03-18T06:54:16.591109Z"
    }
   },
   "id": "3ef690e5fbcd1c22",
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(1024, 3, 1)\n",
    "val_dataset = create_dataset(512, 3, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T06:54:16.695154Z",
     "start_time": "2024-03-18T06:54:16.593660Z"
    }
   },
   "id": "ebfdb7f397c4e856",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class RNNCell(tf.keras.layers.AbstractRNNCell):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.units = units\n",
    "        super(RNNCell, self).__init__(**kwargs)\n",
    "\n",
    "        self.linear = tf.keras.layers.Dense(units)\n",
    "\n",
    "        # layer normalization for trainability\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "        # first recurrent layer in the RNN\n",
    "        self.recurrent_layer = tf.keras.layers.Dense(units,\n",
    "                                                       kernel_initializer= tf.keras.initializers.Orthogonal(\n",
    "                                                           gain=1.0, seed=None),\n",
    "                                                       activation=tf.nn.tanh)\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return [tf.TensorShape([self.units])]\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return [tf.TensorShape([self.units])]\n",
    "\n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        return [tf.zeros([self.units])]\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        prev_output = states[0]\n",
    "        \n",
    "        # linearly project input\n",
    "        x = self.linear(inputs) + prev_output\n",
    "\n",
    "        # apply first recurrent kernel\n",
    "        new_state_layer = self.recurrent_layer(x)\n",
    "\n",
    "        # apply layer norm\n",
    "        x = self.layer_norm(new_state_layer)\n",
    "\n",
    "        # return output and the list of new states of the layers\n",
    "        return x, [new_state_layer]\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"recurrent_units\": self.units}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T06:54:16.699288Z",
     "start_time": "2024-03-18T06:54:16.697528Z"
    }
   },
   "id": "b800ed59ac6d4542",
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class LSTMCell(tf.keras.layers.AbstractRNNCell):\n",
    "    \n",
    "    def __init__(self, input_length=10, hidden_length=20):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_length = input_length\n",
    "        self.hidden_length = hidden_length\n",
    "\n",
    "        # forget gate components\n",
    "        self.linear_forget_w1 = tf.keras.layers.Dense(self.hidden_length, use_bias=True)\n",
    "        self.linear_forget_r1 = tf.keras.layers.Dense(self.hidden_length, use_bias=False)\n",
    "\n",
    "        # input gate components\n",
    "        self.linear_gate_w2 = tf.keras.layers.Dense(self.hidden_length, use_bias=True)\n",
    "        self.linear_gate_r2 = tf.keras.layers.Dense(self.hidden_length, use_bias=False)\n",
    "\n",
    "        # cell memory components\n",
    "        self.linear_gate_w3 = tf.keras.layers.Dense(self.hidden_length, use_bias=True)\n",
    "        self.linear_gate_r3 = tf.keras.layers.Dense(self.hidden_length, use_bias=False)\n",
    "\n",
    "        # out gate components\n",
    "        self.linear_gate_w4 = tf.keras.layers.Dense(self.hidden_length, use_bias=True)\n",
    "        self.linear_gate_r4 = tf.keras.layers.Dense(self.hidden_length, use_bias=False)\n",
    "\n",
    "        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
    "        self.tanh = tf.keras.layers.Activation('tanh')\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return (self.hidden_length, self.hidden_length)\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        h, c = states\n",
    "\n",
    "        # forget gate\n",
    "        f = self.sigmoid(self.linear_forget_w1(inputs) + self.linear_forget_r1(h))\n",
    "\n",
    "        # input gate\n",
    "        i = self.sigmoid(self.linear_gate_w2(inputs) + self.linear_gate_r2(h))\n",
    "\n",
    "        # cell memory\n",
    "        g = self.tanh(self.linear_gate_w3(inputs) + self.linear_gate_r3(h))\n",
    "        c_next = f * c + i * g\n",
    "\n",
    "        # output gate\n",
    "        o = self.sigmoid(self.linear_gate_w4(inputs) + self.linear_gate_r4(h))\n",
    "\n",
    "        # next hidden state\n",
    "        h_next = o * self.tanh(c_next)\n",
    "\n",
    "        return h_next, [h_next, c_next]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T06:54:16.705935Z",
     "start_time": "2024-03-18T06:54:16.702718Z"
    }
   },
   "id": "6803e75adae3ec2d",
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class RNNModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn_cell = LSTMCell(input_length=3, hidden_length=20)\n",
    "\n",
    "        # return_sequences collects and returns the output of the rnn_cell for all time-steps\n",
    "        # unroll unrolls the network for speed (at the cost of memory)\n",
    "        self.rnn_layer = tf.keras.layers.RNN(self.rnn_cell, return_sequences=False, unroll=True)\n",
    "\n",
    "        self.output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "        self.metrics_list = [tf.keras.metrics.Mean(name=\"loss\")]\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_state()\n",
    "\n",
    "    def __call__(self, sequence, training=False):\n",
    "\n",
    "        rnn_output = self.rnn_layer(sequence)\n",
    "\n",
    "        return self.output_layer(rnn_output)\n",
    "\n",
    "    def train_step(self, data):\n",
    "\n",
    "        \"\"\"\n",
    "        Standard train_step method, assuming we use model.compile(optimizer, loss, ...)\n",
    "        \"\"\"\n",
    "\n",
    "        sequence, label = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self(sequence, training=True)\n",
    "            loss = self.compiled_loss(label, output, regularization_losses=self.losses)\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        self.metrics[0].update_state(loss)\n",
    "\n",
    "        return {m.name : m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "\n",
    "        \"\"\"\n",
    "        Standard test_step method, assuming we use model.compile(optimizer, loss, ...)\n",
    "        \"\"\"\n",
    "\n",
    "        sequence, label = data\n",
    "        output = self(sequence, training=False)\n",
    "        loss = self.compiled_loss(label, output, regularization_losses=self.losses)\n",
    "\n",
    "        self.metrics[0].update_state(loss)\n",
    "\n",
    "        return {m.name : m.result() for m in self.metrics}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T06:58:20.221586Z",
     "start_time": "2024-03-18T06:58:20.216869Z"
    }
   },
   "id": "533d7d1aa468e09f",
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = RNNModel()\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-3)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# compile the model (here, adding a loss function and an optimizer)\n",
    "model.compile(optimizer = optimizer, loss=loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T06:58:21.161408Z",
     "start_time": "2024-03-18T06:58:21.142723Z"
    }
   },
   "id": "fa6810d73b196c80",
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"RNN_noise\"\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logging_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"./logs/{EXPERIMENT_NAME}/{current_time}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T06:58:21.727180Z",
     "start_time": "2024-03-18T06:58:21.724657Z"
    }
   },
   "id": "ac8c1482c46871f1",
   "execution_count": 106
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.2285 - val_loss: 0.2854\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 640us/step - loss: 0.2220 - val_loss: 0.2760\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 638us/step - loss: 0.2115 - val_loss: 0.2647\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 588us/step - loss: 0.2038 - val_loss: 0.2560\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 581us/step - loss: 0.1970 - val_loss: 0.2489\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 598us/step - loss: 0.1894 - val_loss: 0.2414\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 620us/step - loss: 0.1827 - val_loss: 0.2354\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 596us/step - loss: 0.1772 - val_loss: 0.2287\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 580us/step - loss: 0.1703 - val_loss: 0.2215\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 577us/step - loss: 0.1650 - val_loss: 0.2173\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 649us/step - loss: 0.1593 - val_loss: 0.2115\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 587us/step - loss: 0.1537 - val_loss: 0.2052\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 578us/step - loss: 0.1484 - val_loss: 0.2004\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 577us/step - loss: 0.1440 - val_loss: 0.1940\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 605us/step - loss: 0.1394 - val_loss: 0.1881\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 596us/step - loss: 0.1343 - val_loss: 0.1831\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 596us/step - loss: 0.1291 - val_loss: 0.1793\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 603us/step - loss: 0.1260 - val_loss: 0.1762\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 613us/step - loss: 0.1213 - val_loss: 0.1715\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 593us/step - loss: 0.1176 - val_loss: 0.1648\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 617us/step - loss: 0.1142 - val_loss: 0.1650\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 652us/step - loss: 0.1112 - val_loss: 0.1584\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 586us/step - loss: 0.1070 - val_loss: 0.1548\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 582us/step - loss: 0.1036 - val_loss: 0.1496\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 587us/step - loss: 0.1008 - val_loss: 0.1477\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 594us/step - loss: 0.0982 - val_loss: 0.1471\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 579us/step - loss: 0.0952 - val_loss: 0.1415\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 579us/step - loss: 0.0921 - val_loss: 0.1352\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 589us/step - loss: 0.0891 - val_loss: 0.1344\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 568us/step - loss: 0.0867 - val_loss: 0.1297\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 597us/step - loss: 0.0848 - val_loss: 0.1264\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 606us/step - loss: 0.0821 - val_loss: 0.1246\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 590us/step - loss: 0.0789 - val_loss: 0.1199\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 595us/step - loss: 0.0764 - val_loss: 0.1174\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 596us/step - loss: 0.0754 - val_loss: 0.1199\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 614us/step - loss: 0.0730 - val_loss: 0.1119\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 597us/step - loss: 0.0707 - val_loss: 0.1117\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 584us/step - loss: 0.0686 - val_loss: 0.1071\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 598us/step - loss: 0.0663 - val_loss: 0.1055\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 617us/step - loss: 0.0647 - val_loss: 0.1022\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 571us/step - loss: 0.0637 - val_loss: 0.1041\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 576us/step - loss: 0.0618 - val_loss: 0.0975\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 579us/step - loss: 0.0600 - val_loss: 0.0950\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 575us/step - loss: 0.0583 - val_loss: 0.0934\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 568us/step - loss: 0.0566 - val_loss: 0.0913\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 603us/step - loss: 0.0545 - val_loss: 0.0893\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 576us/step - loss: 0.0534 - val_loss: 0.0874\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 569us/step - loss: 0.0518 - val_loss: 0.0851\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 588us/step - loss: 0.0502 - val_loss: 0.0833\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 591us/step - loss: 0.0489 - val_loss: 0.0819\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 583us/step - loss: 0.0476 - val_loss: 0.0806\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 612us/step - loss: 0.0464 - val_loss: 0.0806\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 599us/step - loss: 0.0455 - val_loss: 0.0766\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 582us/step - loss: 0.0438 - val_loss: 0.0743\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 587us/step - loss: 0.0432 - val_loss: 0.0730\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 579us/step - loss: 0.0417 - val_loss: 0.0717\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 602us/step - loss: 0.0407 - val_loss: 0.0704\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 588us/step - loss: 0.0395 - val_loss: 0.0685\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 583us/step - loss: 0.0386 - val_loss: 0.0666\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 597us/step - loss: 0.0379 - val_loss: 0.0656\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 601us/step - loss: 0.0371 - val_loss: 0.0641\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 589us/step - loss: 0.0356 - val_loss: 0.0626\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 595us/step - loss: 0.0348 - val_loss: 0.0623\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 607us/step - loss: 0.0340 - val_loss: 0.0601\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 583us/step - loss: 0.0335 - val_loss: 0.0589\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 567us/step - loss: 0.0323 - val_loss: 0.0579\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 586us/step - loss: 0.0321 - val_loss: 0.0561\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 570us/step - loss: 0.0307 - val_loss: 0.0547\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 579us/step - loss: 0.0299 - val_loss: 0.0542\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 583us/step - loss: 0.0293 - val_loss: 0.0524\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 618us/step - loss: 0.0289 - val_loss: 0.0510\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 571us/step - loss: 0.0281 - val_loss: 0.0503\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 592us/step - loss: 0.0278 - val_loss: 0.0538\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 605us/step - loss: 0.0272 - val_loss: 0.0481\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 581us/step - loss: 0.0257 - val_loss: 0.0470\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 573us/step - loss: 0.0253 - val_loss: 0.0465\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 596us/step - loss: 0.0246 - val_loss: 0.0457\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 572us/step - loss: 0.0247 - val_loss: 0.0446\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 584us/step - loss: 0.0235 - val_loss: 0.0431\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 585us/step - loss: 0.0233 - val_loss: 0.0425\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 566us/step - loss: 0.0225 - val_loss: 0.0416\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 583us/step - loss: 0.0219 - val_loss: 0.0402\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 574us/step - loss: 0.0219 - val_loss: 0.0396\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 588us/step - loss: 0.0208 - val_loss: 0.0392\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 586us/step - loss: 0.0212 - val_loss: 0.0382\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 575us/step - loss: 0.0201 - val_loss: 0.0371\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 575us/step - loss: 0.0193 - val_loss: 0.0361\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 585us/step - loss: 0.0193 - val_loss: 0.0359\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 579us/step - loss: 0.0191 - val_loss: 0.0349\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 571us/step - loss: 0.0183 - val_loss: 0.0341\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 574us/step - loss: 0.0182 - val_loss: 0.0337\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 571us/step - loss: 0.0181 - val_loss: 0.0333\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 577us/step - loss: 0.0178 - val_loss: 0.0320\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 593us/step - loss: 0.0172 - val_loss: 0.0312\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 571us/step - loss: 0.0164 - val_loss: 0.0313\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 589us/step - loss: 0.0167 - val_loss: 0.0296\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 582us/step - loss: 0.0160 - val_loss: 0.0296\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 590us/step - loss: 0.0157 - val_loss: 0.0297\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 567us/step - loss: 0.0151 - val_loss: 0.0277\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 582us/step - loss: 0.0148 - val_loss: 0.0276\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 577us/step - loss: 0.0147 - val_loss: 0.0270\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 583us/step - loss: 0.0145 - val_loss: 0.0260\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 588us/step - loss: 0.0142 - val_loss: 0.0274\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 579us/step - loss: 0.0170 - val_loss: 0.0269\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 579us/step - loss: 0.0148 - val_loss: 0.0245\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 588us/step - loss: 0.0135 - val_loss: 0.0238\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 569us/step - loss: 0.0138 - val_loss: 0.0239\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 575us/step - loss: 0.0126 - val_loss: 0.0231\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 588us/step - loss: 0.0126 - val_loss: 0.0231\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 594us/step - loss: 0.0126 - val_loss: 0.0223\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 609us/step - loss: 0.0123 - val_loss: 0.0217\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 593us/step - loss: 0.0116 - val_loss: 0.0210\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 636us/step - loss: 0.0116 - val_loss: 0.0206\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 599us/step - loss: 0.0116 - val_loss: 0.0200\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 639us/step - loss: 0.0109 - val_loss: 0.0207\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 634us/step - loss: 0.0113 - val_loss: 0.0193\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 640us/step - loss: 0.0106 - val_loss: 0.0186\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 601us/step - loss: 0.0105 - val_loss: 0.0194\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 601us/step - loss: 0.0103 - val_loss: 0.0179\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 613us/step - loss: 0.0101 - val_loss: 0.0177\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 581us/step - loss: 0.0097 - val_loss: 0.0170\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 606us/step - loss: 0.0099 - val_loss: 0.0168\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 624us/step - loss: 0.0103 - val_loss: 0.0181\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 590us/step - loss: 0.0105 - val_loss: 0.0159\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 580us/step - loss: 0.0095 - val_loss: 0.0159\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 593us/step - loss: 0.0091 - val_loss: 0.0152\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 637us/step - loss: 0.0089 - val_loss: 0.0180\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 595us/step - loss: 0.0090 - val_loss: 0.0147\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 592us/step - loss: 0.0086 - val_loss: 0.0141\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 589us/step - loss: 0.0083 - val_loss: 0.0148\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 602us/step - loss: 0.0088 - val_loss: 0.0136\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 587us/step - loss: 0.0082 - val_loss: 0.0134\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 578us/step - loss: 0.0077 - val_loss: 0.0127\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 596us/step - loss: 0.0079 - val_loss: 0.0127\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 594us/step - loss: 0.0078 - val_loss: 0.0125\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 578us/step - loss: 0.0080 - val_loss: 0.0122\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 573us/step - loss: 0.0073 - val_loss: 0.0116\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 590us/step - loss: 0.0074 - val_loss: 0.0116\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 592us/step - loss: 0.0072 - val_loss: 0.0115\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 583us/step - loss: 0.0070 - val_loss: 0.0108\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 590us/step - loss: 0.0073 - val_loss: 0.0105\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 579us/step - loss: 0.0067 - val_loss: 0.0108\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 570us/step - loss: 0.0065 - val_loss: 0.0102\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 612us/step - loss: 0.0064 - val_loss: 0.0099\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 586us/step - loss: 0.0063 - val_loss: 0.0098\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 601us/step - loss: 0.0060 - val_loss: 0.0100\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 617us/step - loss: 0.0062 - val_loss: 0.0097\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 593us/step - loss: 0.0059 - val_loss: 0.0091\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 580us/step - loss: 0.0058 - val_loss: 0.0084\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 589us/step - loss: 0.0058 - val_loss: 0.0084\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 576us/step - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 591us/step - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 616us/step - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 591us/step - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 584us/step - loss: 0.0052 - val_loss: 0.0072\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 651us/step - loss: 0.0054 - val_loss: 0.0073\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 646us/step - loss: 0.0050 - val_loss: 0.0068\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 648us/step - loss: 0.0053 - val_loss: 0.0073\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 634us/step - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 602us/step - loss: 0.0056 - val_loss: 0.0063\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 598us/step - loss: 0.0050 - val_loss: 0.0079\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 584us/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 569us/step - loss: 0.0046 - val_loss: 0.0064\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 579us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 585us/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 593us/step - loss: 0.0045 - val_loss: 0.0072\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 662us/step - loss: 0.0047 - val_loss: 0.0063\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 707us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 593us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 609us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 624us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 586us/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 640us/step - loss: 0.0040 - val_loss: 0.0052\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 636us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 602us/step - loss: 0.0043 - val_loss: 0.0065\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 612us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 594us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 609us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 583us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 580us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 609us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 591us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 598us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 587us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 613us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 578us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 576us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 639us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 591us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 643us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 607us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 592us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 603us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 579us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 582us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 600us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 587us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 588us/step - loss: 0.0030 - val_loss: 0.0023\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    initial_epoch=0,\n",
    "                    epochs=200,\n",
    "                    callbacks=[logging_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T06:58:36.528515Z",
     "start_time": "2024-03-18T06:58:32.306675Z"
    }
   },
   "id": "ea7da146970ef62",
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 07:54:52.795982: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,3,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2024-03-18 07:54:52.808443: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,3,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2024-03-18 07:54:52.812996: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sequence' with dtype float and shape [?,3,1]\n",
      "\t [[{{node sequence}}]]\n",
      "2024-03-18 07:54:52.816459: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,3,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2024-03-18 07:54:52.820082: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sequence' with dtype float and shape [?,3,1]\n",
      "\t [[{{node sequence}}]]\n",
      "2024-03-18 07:54:52.823232: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,3,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2024-03-18 07:54:52.826407: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,3,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-18 07:54:52.829994: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,3,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-18 07:54:52.839209: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sequence' with dtype float and shape [?,3,1]\n",
      "\t [[{{node sequence}}]]\n",
      "2024-03-18 07:54:52.842447: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sequence' with dtype float and shape [?,3,1]\n",
      "\t [[{{node sequence}}]]\n",
      "2024-03-18 07:54:52.850908: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,3,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2024-03-18 07:54:52.854496: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sequence' with dtype float and shape [?,3,1]\n",
      "\t [[{{node sequence}}]]\n",
      "2024-03-18 07:54:52.857504: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sequence' with dtype float and shape [?,3,1]\n",
      "\t [[{{node sequence}}]]\n",
      "2024-03-18 07:54:52.928722: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,3,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-18 07:54:52.931638: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,3,1]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as dense_36_layer_call_fn, dense_36_layer_call_and_return_conditional_losses, dense_37_layer_call_fn, dense_37_layer_call_and_return_conditional_losses, dense_38_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 07:54:53.006451: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_input_1' with dtype float and shape [?,3,1]\n",
      "\t [[{{node serving_default_input_1}}]]\n",
      "INFO:tensorflow:Assets written to: saved_model/assets\n",
      "WARNING:absl:<__main__.LSTMCell object at 0x160403520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class '__main__.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# save the complete model (incl. optimizer state, loss function, metrics etc.)\n",
    "# ideally save to google drive if you're using colab\n",
    "model.save(\"saved_model\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T06:54:53.164333Z",
     "start_time": "2024-03-18T06:54:52.733239Z"
    }
   },
   "id": "c9efef9fb83a2f4e",
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend(labels=[\"training\",\"validation\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Binary Crossentropy Loss\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T06:54:53.956163Z",
     "start_time": "2024-03-18T06:54:53.894174Z"
    }
   },
   "id": "5987439449ab87c5",
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T06:54:17.862894Z",
     "start_time": "2024-03-18T06:54:17.831827Z"
    }
   },
   "id": "49b83001167afbd6",
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Reusing TensorBoard on port 6006 (pid 1541), started 0:03:49 ago. (Use '!kill 1541' to kill it.)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-d0b4446e85fd0b32\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-d0b4446e85fd0b32\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=\"logs/RNN_noise\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T06:54:17.893907Z",
     "start_time": "2024-03-18T06:54:17.864653Z"
    }
   },
   "id": "c19663cf1e14f56c",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T06:54:17.901939Z",
     "start_time": "2024-03-18T06:54:17.875877Z"
    }
   },
   "id": "322e24faa08e621c",
   "execution_count": 96
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

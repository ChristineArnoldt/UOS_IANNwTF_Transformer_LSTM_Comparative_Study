{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:59:27.961287Z",
     "start_time": "2024-03-26T17:59:27.955727Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#-----------HYPERPARAMETERS----------------#\n",
    "\n",
    "SEQUENCE_LENGTH = [2, 4, 8, 16, 32]\n",
    "HIDDEN_LENGTH = 20\n",
    "N_FEATURES = 1\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 100\n",
    "NUM_OF_LAYERS = 3\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:59:28.410109Z",
     "start_time": "2024-03-26T17:59:28.408158Z"
    }
   },
   "id": "ebaea4cd2610d233",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_dataset_for_sum_prediction(n_samples, sequence_length, n_features, validation):\n",
    "    \"\"\"\n",
    "    Function to create a dataset for the sum prediction task. The function generates random integers between 0 and 10 and calculates the sum of the sequence\n",
    "    :param n_samples:  number of samples in the dataset\n",
    "    :param sequence_length: length of the sequence\n",
    "    :param n_features: number of features in the sequence\n",
    "    :return: a tf.data.Dataset object containing the input and output pairs\n",
    "    \"\"\"\n",
    "    x = tf.cast(np.random.randint(low=0, high=11, size=(n_samples, sequence_length, n_features)), tf.float32)\n",
    "    sums = []\n",
    "    for sample in range(n_samples):\n",
    "        value = x[sample, :, :]\n",
    "        sums.append(tf.reduce_sum(value))\n",
    "    y = tf.cast(tf.expand_dims(tf.convert_to_tensor(sums), axis=1), tf.float32)\n",
    "    if not validation:\n",
    "        return tf.data.Dataset.from_tensor_slices((x, y)).shuffle(n_samples).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    else:\n",
    "        return tf.data.Dataset.from_tensor_slices((x, y)).batch(512).prefetch(tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:59:28.900416Z",
     "start_time": "2024-03-26T17:59:28.897393Z"
    }
   },
   "id": "3ef690e5fbcd1c22",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_dataset_for_cum_sum_prediction(n_samples, sequence_length, n_features, validation):\n",
    "    \"\"\"\n",
    "    Function to create a dataset for the cumulative sum prediction task. The function generates random integers between 0 and 10 and calculates the cumulative sum of the sequence\n",
    "    :param n_samples: number of samples in the dataset\n",
    "    :param sequence_length: length of the sequence\n",
    "    :param n_features: number of features in the sequence\n",
    "    :return: a tf.data.Dataset object containing the input and output pairs\n",
    "    \"\"\"\n",
    "    x = tf.cast(np.random.randint(low=0, high=11, size=(n_samples, sequence_length, n_features)), tf.float32)\n",
    "    sums = []\n",
    "    for sample in range(n_samples):\n",
    "        value = x[sample, :, :]\n",
    "        sums.append(tf.cumsum(value, axis=0))\n",
    "    y = tf.cast(tf.convert_to_tensor(sums), tf.float32)\n",
    "    if not validation:\n",
    "        return tf.data.Dataset.from_tensor_slices((x, y)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    else:\n",
    "        return tf.data.Dataset.from_tensor_slices((x, y)).shuffle(n_samples).batch(512).prefetch(tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:59:30.354998Z",
     "start_time": "2024-03-26T17:59:30.350410Z"
    }
   },
   "id": "b626d56c5abe3958",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LSTMCell(tf.keras.layers.AbstractRNNCell):\n",
    "    \"\"\"\n",
    "    Custom LSTM cell implementation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_length, hidden_length):\n",
    "        \"\"\"\n",
    "        Initializes the LSTM cell with input and hidden dimensions\n",
    "        \n",
    "        :param input_length: Length of the input vector\n",
    "        :param hidden_length: Length of the hidden state vector\n",
    "        \"\"\"\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_length = input_length\n",
    "        self.hidden_length = hidden_length\n",
    "\n",
    "        # forget gate components\n",
    "        self.linear_forget_w1 = tf.keras.layers.Dense(self.hidden_length, use_bias=True)\n",
    "        self.linear_forget_r1 = tf.keras.layers.Dense(self.hidden_length, use_bias=False)\n",
    "\n",
    "        # input gate components\n",
    "        self.linear_gate_w2 = tf.keras.layers.Dense(self.hidden_length, use_bias=True)\n",
    "        self.linear_gate_r2 = tf.keras.layers.Dense(self.hidden_length, use_bias=False)\n",
    "\n",
    "        # cell memory components\n",
    "        self.linear_gate_w3 = tf.keras.layers.Dense(self.hidden_length, use_bias=True)\n",
    "        self.linear_gate_r3 = tf.keras.layers.Dense(self.hidden_length, use_bias=False)\n",
    "\n",
    "        # out gate components\n",
    "        self.linear_gate_w4 = tf.keras.layers.Dense(self.hidden_length, use_bias=True)\n",
    "        self.linear_gate_r4 = tf.keras.layers.Dense(self.hidden_length, use_bias=False)\n",
    "\n",
    "        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
    "        self.tanh = tf.keras.layers.Activation('tanh')\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        \"\"\"\n",
    "        Returns the size of the LSTM cell state\n",
    "        \"\"\"\n",
    "        return self.hidden_length, self.hidden_length\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        \"\"\"\n",
    "        Performs the forward pass through the LSTM cell\n",
    "        \n",
    "        :param inputs: Input tensor\n",
    "        :param states: Tuple containing the previous hidden state and cell state\n",
    "        \"\"\"\n",
    "        \n",
    "        h, c = states\n",
    "\n",
    "        # forget gate\n",
    "        f = self.sigmoid(self.linear_forget_w1(inputs) + self.linear_forget_r1(h))\n",
    "\n",
    "        # input gate\n",
    "        i = self.sigmoid(self.linear_gate_w2(inputs) + self.linear_gate_r2(h))\n",
    "\n",
    "        # cell memory\n",
    "        g = self.tanh(self.linear_gate_w3(inputs) + self.linear_gate_r3(h))\n",
    "        c_next = f * c + i * g\n",
    "\n",
    "        # output gate\n",
    "        o = self.sigmoid(self.linear_gate_w4(inputs) + self.linear_gate_r4(h))\n",
    "\n",
    "        # next hidden state\n",
    "        h_next = o * self.tanh(c_next)\n",
    "\n",
    "        return h_next, [h_next, c_next]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:59:31.979061Z",
     "start_time": "2024-03-26T17:59:31.970961Z"
    }
   },
   "id": "6803e75adae3ec2d",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class RNNModel(tf.keras.Model):\n",
    "    def __init__(self, num_layers, sequence_length, hidden_length, cumsum):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cumsum = cumsum\n",
    "        \n",
    "        self.rnn_cell = LSTMCell(input_length=sequence_length, hidden_length=hidden_length)\n",
    "        \n",
    "        self.rnn_layer = tf.keras.layers.RNN(self.rnn_cell, return_sequences=cumsum, unroll=True)\n",
    "        \n",
    "        if cumsum:\n",
    "            self.output_layer = tf.keras.layers.Dense(sequence_length)\n",
    "        else:\n",
    "            self.output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "        self.metrics_list = [tf.keras.metrics.Mean(name=\"loss\")]\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE)\n",
    "        \n",
    "        self.loss_function = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_state()\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, sequence, training=False):\n",
    "\n",
    "        x = self.rnn_layer(sequence)\n",
    "\n",
    "        return self.output_layer(x)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        \"\"\"\n",
    "        Standard train_step method\n",
    "        :param data: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "\n",
    "        sequence, label = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self.call(sequence, training=True)\n",
    "            loss = self.loss_function(label, output) + tf.reduce_sum(self.losses)\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "\n",
    "        self.optimizer.apply_gradients(grads_and_vars=zip(gradients, self.trainable_variables))\n",
    "\n",
    "        self.metrics[0].update_state(loss)\n",
    "\n",
    "        return {m.name : m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        \"\"\"\n",
    "        Standard test_step method\n",
    "        :param data: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "\n",
    "        sequence, label = data\n",
    "        output = self.call(sequence, training=False)\n",
    "        loss = self.loss_function(label, output) + tf.reduce_sum(self.losses)\n",
    "\n",
    "        self.metrics[0].update_state(loss)\n",
    "\n",
    "        return {m.name : m.result() for m in self.metrics}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:59:33.586824Z",
     "start_time": "2024-03-26T17:59:33.578266Z"
    }
   },
   "id": "533d7d1aa468e09f",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#----------Training------------#\n",
    "\n",
    "import tqdm\n",
    "\n",
    "def training_loop(model, train, test, train_summary_writer, test_summary_writer):\n",
    "    # Lists to store training and validation metrics across epochs\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    # Loop through epochs\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        # Training\n",
    "        for data in tqdm.tqdm(train, position=0, leave=False, desc=f\"Epoch {epoch}\"):\n",
    "            # Perform a training step using the model\n",
    "            metrics = model.train_step(data)\n",
    "\n",
    "            # Log training metrics to TensorBoard\n",
    "            with train_summary_writer.as_default():\n",
    "                for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=epoch)\n",
    "\n",
    "        # Store training metrics for the epoch\n",
    "        train_loss.append(metrics[\"loss\"].numpy())\n",
    "\n",
    "        # Print and reset training metrics\n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"EPOCH {epoch}\")\n",
    "            print([f\"{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "        model.reset_metrics()\n",
    "\n",
    "        # Testing\n",
    "        for data in test:\n",
    "            # Perform a testing step using the model\n",
    "            metrics = model.test_step(data)\n",
    "\n",
    "            # Log validation metrics to TensorBoard\n",
    "            with test_summary_writer.as_default():\n",
    "                for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=epoch)\n",
    "\n",
    "        # Store validation metrics for the epoch\n",
    "        val_loss.append(metrics[\"loss\"].numpy())\n",
    "\n",
    "        # Print validation metrics\n",
    "        if epoch % 20 == 0:\n",
    "            print([f\"val_{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "\n",
    "        # Reset validation metrics\n",
    "        model.reset_metrics()\n",
    "\n",
    "    # Return lists of training and validation metrics for analysis or plotting\n",
    "    return train_loss, train_acc, val_loss, val_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:59:36.623042Z",
     "start_time": "2024-03-26T17:59:36.616975Z"
    }
   },
   "id": "c17bae30bd3e804b",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#-----------SUM PREDICTION FOR DIFFERENT SEQUENCE LENGTH----------------#\n",
    "\n",
    "config_name= \"LSTM_SUM_PREDICTION\"\n",
    "\n",
    "for length in SEQUENCE_LENGTH:\n",
    "    train_dataset = create_dataset_for_sum_prediction(1024, length, 1, False)\n",
    "    val_dataset = create_dataset_for_sum_prediction(512, length, 1, True)\n",
    "    \n",
    "    train_log_path = f\"logs/{config_name}/{length}/train\"\n",
    "    test_log_path = f\"logs/{config_name}/{length}/val\"\n",
    "    \n",
    "    # log writer for training metrics\n",
    "    train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "    \n",
    "    # log writer for validation metrics\n",
    "    test_summary_writer = tf.summary.create_file_writer(test_log_path)\n",
    "    \n",
    "    model = RNNModel(num_layers=NUM_OF_LAYERS, sequence_length=length, hidden_length=HIDDEN_LENGTH, cumsum=False)\n",
    "    train_losses, train_accuracies, val_losses, val_accuracies = training_loop(model, train_dataset, val_dataset, train_summary_writer, test_summary_writer)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b12fbf54176ec1ef",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#-----------CUMSUM PREDICTION FOR DIFFERENT SEQUENCE LENGTH----------------#\n",
    "\n",
    "config_name= \"LSTM_CUMSUM_prediction\"\n",
    "\n",
    "for length in SEQUENCE_LENGTH:\n",
    "    train_dataset = create_dataset_for_cum_sum_prediction(1024, length, 1, False)\n",
    "    val_dataset = create_dataset_for_cum_sum_prediction(512, length, 1, True)\n",
    "    \n",
    "    train_log_path = f\"logs/{config_name}/{length}/train\"\n",
    "    test_log_path = f\"logs/{config_name}/{length}/val\"\n",
    "    \n",
    "    # log writer for training metrics\n",
    "    train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "    \n",
    "    # log writer for validation metrics\n",
    "    test_summary_writer = tf.summary.create_file_writer(test_log_path)\n",
    "    \n",
    "    model = RNNModel(num_layers=NUM_OF_LAYERS, sequence_length=length, hidden_length=HIDDEN_LENGTH, cumsum=True)\n",
    "    train_losses, train_accuracies, val_losses, val_accuracies = training_loop(model, train_dataset, val_dataset, train_summary_writer, test_summary_writer)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52d485958f70239e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:07:51.187182Z",
     "start_time": "2024-03-26T18:07:51.183769Z"
    }
   },
   "id": "49b83001167afbd6",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-d1780fbbd28bdb00\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-d1780fbbd28bdb00\");\n          const url = new URL(\"/\", window.location);\n          const port = 6009;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=\"logs/LSTM_SUM_PREDICTION\" --port=6009"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:08:12.783912Z",
     "start_time": "2024-03-26T18:08:10.239272Z"
    }
   },
   "id": "c19663cf1e14f56c",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-e1614e058f8bc1fe\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-e1614e058f8bc1fe\");\n          const url = new URL(\"/\", window.location);\n          const port = 6004;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=\"logs/LSTM_CUMSUM_prediction\" --port=6004"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:08:24.004769Z",
     "start_time": "2024-03-26T18:08:21.477019Z"
    }
   },
   "id": "892465b702ff313b",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "#-----------Loop for different sequence lengths with compile and fit----------------#\n",
    "\n",
    "for length in SEQUENCE_LENGTH:\n",
    "    train_dataset = create_dataset_for_cum_sum_prediction(1024, length, 1, False)\n",
    "    val_dataset = create_dataset_for_cum_sum_prediction(512, length, 1, True)\n",
    "    \n",
    "    model = RNNModel(num_layers=NUM_OF_LAYERS, sequence_length=length, hidden_length=HIDDEN_LENGTH, cumsum=True)\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE)\n",
    "    loss = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer = optimizer, loss=loss)\n",
    "    \n",
    "    EXPERIMENT_NAME = \"LSTM_sum_prediction\"\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    logging_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"./logs/{EXPERIMENT_NAME}/{length}\")\n",
    "    \n",
    "    history = model.fit(train_dataset, \n",
    "                        validation_data=val_dataset,\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=[logging_callback],\n",
    "                        verbose=0)\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abe754ee3ed4ac77"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

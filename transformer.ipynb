{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------HYPERPARAMETERS----------------#\n",
    "\n",
    "SEQUENCE_LENGTH = [2, 4, 8, 16, 32]\n",
    "HIDDEN_LENGTH = 20\n",
    "N_FEATURES = 1\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 100\n",
    "CUMSUM = True\n",
    "NUM_OF_LAYERS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_for_sum_prediction(n_samples, sequence_length, n_features, validation):\n",
    "    \"\"\"\n",
    "    Function to create a dataset for the sum prediction task. The function generates random integers between 0 and 10 and calculates the sum of the sequence\n",
    "    :param n_samples:  number of samples in the dataset\n",
    "    :param sequence_length: length of the sequence\n",
    "    :param n_features: number of features in the sequence\n",
    "    :return: a tf.data.Dataset object containing the input and output pairs\n",
    "    \"\"\"\n",
    "    x = tf.cast(np.random.randint(low=0, high=11, size=(n_samples, sequence_length, n_features)), tf.float32)\n",
    "    sums = []\n",
    "    for sample in range(n_samples):\n",
    "        value = x[sample, :, :]\n",
    "        sums.append(tf.reduce_sum(value))\n",
    "    y = tf.cast(tf.expand_dims(tf.convert_to_tensor(sums), axis=1), tf.float32)\n",
    "    if not validation:\n",
    "        return tf.data.Dataset.from_tensor_slices((x, y)).shuffle(n_samples).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    else:\n",
    "        return tf.data.Dataset.from_tensor_slices((x, y)).batch(512).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_for_cum_sum_prediction(n_samples, sequence_length, n_features, validation):\n",
    "    \"\"\"\n",
    "    Function to create a dataset for the cumulative sum prediction task. The function generates random integers between 0 and 10 and calculates the cumulative sum of the sequence\n",
    "    :param n_samples: number of samples in the dataset\n",
    "    :param sequence_length: length of the sequence\n",
    "    :param n_features: number of features in the sequence\n",
    "    :return: a tf.data.Dataset object containing the input and output pairs\n",
    "    \"\"\"\n",
    "    x = tf.cast(np.random.randint(low=0, high=11, size=(n_samples, sequence_length, n_features)), tf.float32)\n",
    "    sums = []\n",
    "    for sample in range(n_samples):\n",
    "        value = x[sample, :, :]\n",
    "        sums.append(tf.cumsum(value, axis=0))\n",
    "    y = tf.cast(tf.convert_to_tensor(sums), tf.float32)\n",
    "    if not validation:\n",
    "        return tf.data.Dataset.from_tensor_slices((x, y)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    else:\n",
    "        return tf.data.Dataset.from_tensor_slices((x, y)).shuffle(n_samples).batch(512).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    # positional encoding to give model information on relative position of tokens in the sequence\n",
    "    # positional encoding vector is added to  embedding vector\n",
    "    \n",
    "    def __init__(self, position, dim):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, dim)\n",
    "        \n",
    "    def get_angles(self, position, i, dim):\n",
    "        position = tf.cast(position, dtype=tf.float32)\n",
    "        i = tf.cast(i, dtype=tf.float32)\n",
    "        dim = tf.cast(dim, dtype=tf.float32)\n",
    "        \n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(dim, tf.float32))\n",
    "        return position * angles\n",
    "    \n",
    "    def positional_encoding(self, position, dim):\n",
    "        \n",
    "        angle_rads = self.get_angles(\n",
    "            tf.range(position)[:, tf.newaxis],\n",
    "            tf.range(dim)[tf.newaxis, :],\n",
    "            dim\n",
    "        )\n",
    "        \n",
    "        # apply sin to even indices\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # apply cos to odd indices\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "        \n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        \n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.dim = dim\n",
    "        \n",
    "        assert dim % self.num_heads == 0\n",
    "        \n",
    "        self.depth = dim // self.num_heads\n",
    "        \n",
    "        self.weights_query = tf.keras.layers.Dense(dim)\n",
    "        self.weights_key = tf.keras.layers.Dense(dim)\n",
    "        self.weights_value = tf.keras.layers.Dense(dim)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(dim)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, query, key, value, mask):\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        \n",
    "        query = self.weights_query(query)\n",
    "        key = self.weights_key(key)\n",
    "        value = self.weights_value(value)\n",
    "        \n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        \n",
    "        scaled_attention, attention_weights = self.scaled_dot_product_attention(query, key, value, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.dim))\n",
    "        \n",
    "        output = self.dense(concat_attention)\n",
    "        \n",
    "        return output, attention_weights\n",
    "    \n",
    "    def scaled_dot_product_attention(self, query, key, value, mask):\n",
    "        # calc attention weights\n",
    "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "        \n",
    "        # scale tensor and add mask\n",
    "        dk = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        \n",
    "        output = tf.matmul(attention_weights, value)\n",
    "        \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, dim, num_heads, dim_feedforward, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.multiheadattention = MultiHeadAttention(dim, num_heads)\n",
    "    self.ffn = self.feed_forward(dim, dim_feedforward)\n",
    "\n",
    "    self.normalization1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.normalization2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "  \n",
    "  def feed_forward(self, dim, dim_feedforward):\n",
    "    inputs = tf.keras.Input(shape=(None, dim), name=\"inputs\")\n",
    "    dense1 = tf.keras.layers.Dense(dim_feedforward, activation='relu')(inputs)\n",
    "    outputs = tf.keras.layers.Dense(dim)(dense1)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attention_output, _ = self.multiheadattention(x, x, x, mask) \n",
    "    attention_output = self.dropout1(attention_output, training=training)\n",
    "    out1 = self.normalization1(x + attention_output) \n",
    "    \n",
    "    ffn_output = self.ffn(out1)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.normalization2(out1 + ffn_output) \n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, dim, num_heads, dim_feedforward, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.multiheadattention1 = MultiHeadAttention(dim, num_heads)\n",
    "    self.multiheadattention2 = MultiHeadAttention(dim, num_heads)\n",
    "\n",
    "    self.ffn = self.feed_forward(dim, dim_feedforward)\n",
    " \n",
    "    self.normalization1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.normalization2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.normalization3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "  \n",
    "  def feed_forward(self, dim, dim_feedforward):\n",
    "    inputs = tf.keras.Input(shape=(None, dim), name=\"inputs\")\n",
    "    dense1 = tf.keras.layers.Dense(dim_feedforward, activation='relu')(inputs)\n",
    "    outputs = tf.keras.layers.Dense(dim)(dense1)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attention1, attention_weights1 = self.multiheadattention1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attention1 = self.dropout1(attention1, training=training)\n",
    "    out1 = self.normalization1(attention1 + x)\n",
    "    \n",
    "    attention2, attention_weights2 = self.multiheadattention2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attention2 = self.dropout2(attention2, training=training)\n",
    "    out2 = self.normalization2(attention2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.normalization3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attention_weights1, attention_weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, dim, num_heads, dim_feedforward, input_vocab_size,\n",
    "               position, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.dim = dim\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, dim)\n",
    "    self.pos_encoding = PositionalEncoding(position, self.dim)\n",
    "    \n",
    "    self.encoder = [EncoderLayer(dim, num_heads, dim_feedforward, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # adding embeddings\n",
    "    x = self.embedding(x)\n",
    "    x *= tf.math.sqrt(tf.cast(self.dim, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.encoder[i](x, training, mask)\n",
    "    \n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, dim, num_heads, dim_feedforward, target_vocab_size,\n",
    "               position, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.dim = dim\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, dim)\n",
    "    self.pos_encoding = PositionalEncoding(position, dim)\n",
    "    \n",
    "    self.decoder = [DecoderLayer(dim, num_heads, dim_feedforward, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.decoder[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(tf.keras.Model):\n",
    "    def __init__(self, num_layers: int, dim: int, num_heads: int, dim_feedforward: int,input_vocab_size: int, target_vocab_size: int, rate=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "     \n",
    "        self.encoder = Encoder(num_layers, dim, num_heads, dim_feedforward, \n",
    "                           input_vocab_size, position=input_vocab_size, rate=rate)\n",
    "        self.decoder = Decoder(num_layers, dim, num_heads, dim_feedforward, \n",
    "                            target_vocab_size, position=target_vocab_size, rate=rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "        \n",
    "        self.metrics_list = [tf.keras.metrics.Mean(name=\"loss\")]\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "        self.loss_function = tf.keras.losses.MeanAbsoluteError()\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_state()\n",
    "    \n",
    "    def create_masks(self, inp, tar):\n",
    "        seq = tf.cast(tf.math.equal(inp, 0), tf.float32)\n",
    "        padding_mask = seq[:, tf.newaxis, tf.newaxis, :]\n",
    "        \n",
    "        target_size = tf.shape(tar)[1]\n",
    "        look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((target_size, target_size)), -1, 0)\n",
    "\n",
    "        seq_target = tf.cast(tf.math.equal(tar, 0), tf.float32)\n",
    "        target_padding_mask = seq_target[:, tf.newaxis, tf.newaxis, :]\n",
    "        future_token_mask = tf.maximum(target_padding_mask, look_ahead_mask)\n",
    "        \n",
    "        return padding_mask, future_token_mask\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input, target, padding_mask, \n",
    "            look_ahead_mask, training=False):\n",
    "\n",
    "        enc_output = self.encoder(input, training, padding_mask)  \n",
    "        dec_output, attention_weights = self.decoder(target, enc_output, training, look_ahead_mask, padding_mask)\n",
    "        \n",
    "        final_output = self.final_layer(dec_output)\n",
    "        \n",
    "        return final_output, attention_weights\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        \"\"\"\n",
    "        Standard train_step method\n",
    "        :param data: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        sequence, label = data\n",
    "\n",
    "        #prep seq & labels for seq2seq model: shifting so model learns to predict next token in sequence\n",
    "        # remove last token from each target sequence\n",
    "        # creates sequences shifted by one position compared to original targets for decoder input\n",
    "        tar_inp = label[:, :-1]\n",
    "        # remove first token from each target sequence\n",
    "        # creates sequences shifted by one position compared to original targets as expected outputs for each input sequence & to compute loss\n",
    "        tar_real = label[:, 1:]\n",
    "        \n",
    "        padding_mask, look_ahead_mask = self.create_masks(sequence, tar_inp)\n",
    "  \n",
    "        with tf.GradientTape() as tape:\n",
    "            output, _ = self.call(sequence, tar_inp, padding_mask, look_ahead_mask, training=True)\n",
    "            loss = self.loss_function(tar_real, output) + tf.reduce_sum(self.losses)\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "\n",
    "        self.optimizer.apply_gradients(grads_and_vars=zip(gradients, self.trainable_variables))\n",
    "\n",
    "        self.metrics[0].update_state(loss)\n",
    "\n",
    "        return {m.name : m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        \"\"\"\n",
    "        Standard test_step method\n",
    "        :param data: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        sequence, label = data\n",
    "        \n",
    "         #prep seq & labels for seq2seq model: shifting so model learns to predict next token in sequence\n",
    "        # remove last token from each target sequence\n",
    "        # creates sequences shifted by one position compared to original targets for decoder input\n",
    "        tar_inp = label[:, :-1]\n",
    "        # remove first token from each target sequence\n",
    "        # creates sequences shifted by one position compared to original targets as expected outputs for each input sequence & to compute loss\n",
    "        tar_real = label[:, 1:]\n",
    "        \n",
    "        padding_mask, look_ahead_mask = self.create_masks(sequence, tar_inp)\n",
    "  \n",
    "        self.call(sequence, tar_inp, padding_mask, look_ahead_mask, training=True)\n",
    "        \n",
    "\n",
    "        # Forward pass through the model\n",
    "        predictions, _ = self.call(sequence, tar_inp,\n",
    "                                    False,  # Ensure no dropout during inference\n",
    "                                    padding_mask,\n",
    "                                    look_ahead_mask)\n",
    "\n",
    "        # Compute loss and metrics\n",
    "        loss = self.loss_function(tar_real, predictions) #+ tf.reduce_sum(self.losses)\n",
    "        self.metrics[0].update_state(loss)\n",
    "\n",
    "        return {m.name : m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------Training------------#\n",
    "\n",
    "import tqdm\n",
    "\n",
    "def training_loop(model, train, test, train_summary_writer, test_summary_writer):\n",
    "    # Lists to store training and validation metrics across epochs\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    # Loop through epochs\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        # Training\n",
    "        for data in tqdm.tqdm(train, position=0, leave=False, desc=f\"Epoch {epoch}\"):\n",
    "            # Perform a training step using the model\n",
    "            metrics = model.train_step(data)\n",
    "\n",
    "            # Log training metrics to TensorBoard\n",
    "            with train_summary_writer.as_default():\n",
    "                for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=epoch)\n",
    "\n",
    "        # Store training metrics for the epoch\n",
    "        train_loss.append(metrics[\"loss\"].numpy())\n",
    "\n",
    "        # Print and reset training metrics\n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"EPOCH {epoch}\")\n",
    "            print([f\"{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "        model.reset_metrics()\n",
    "\n",
    "        # Testing\n",
    "        for data in test:\n",
    "            # Perform a testing step using the model\n",
    "            metrics = model.test_step(data)\n",
    "\n",
    "            # Log validation metrics to TensorBoard\n",
    "            with test_summary_writer.as_default():\n",
    "                for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=epoch)\n",
    "\n",
    "        # Store validation metrics for the epoch\n",
    "        val_loss.append(metrics[\"loss\"].numpy())\n",
    "\n",
    "        # Print validation metrics\n",
    "        if epoch % 20 == 0:\n",
    "            print([f\"val_{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "\n",
    "        # Reset validation metrics\n",
    "        model.reset_metrics()\n",
    "\n",
    "    # Return lists of training and validation metrics for analysis or plotting\n",
    "    return train_loss, train_acc, val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/var/folders/p8/rh_91kl969g6rhp4ksqdmjhr0000gn/T/ipykernel_18354/2046511709.py\", line 41, in call  *\n        enc_output = self.encoder(input, training, padding_mask)\n    File \"/Users/christinearnoldt/mambaforge/envs/iannwtf_final_project/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/christinearnoldt/mambaforge/envs/iannwtf_final_project/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 721, in __call__\n        raise ValueError(\n\n    ValueError: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: True (of type <class 'bool'>)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m test_summary_writer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mcreate_file_writer(test_log_path)\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m TransformerModel(num_layers\u001b[38;5;241m=\u001b[39mNUM_OF_LAYERS, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, dim_feedforward\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m, input_vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8500\u001b[39m, target_vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8000\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m train_losses, train_accuracies, val_losses, val_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_summary_writer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_summary_writer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[38], line 18\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, train, test, train_summary_writer, test_summary_writer)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(train, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# Perform a training step using the model\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# Log training metrics to TensorBoard\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m train_summary_writer\u001b[38;5;241m.\u001b[39mas_default():\n",
      "Cell \u001b[0;32mIn[37], line 67\u001b[0m, in \u001b[0;36mTransformerModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     64\u001b[0m padding_mask, look_ahead_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_masks(sequence, tar_inp)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 67\u001b[0m     output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtar_inp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function(tar_real, output) \u001b[38;5;241m+\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n\u001b[1;32m     69\u001b[0m gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables)\n",
      "File \u001b[0;32m~/mambaforge/envs/iannwtf_final_project/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/p8/rh_91kl969g6rhp4ksqdmjhr0000gn/T/__autograph_generated_filerimjl3ls.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input, target, padding_mask, look_ahead_mask, training)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m enc_output \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m dec_output, attention_weights \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdecoder, (ag__\u001b[38;5;241m.\u001b[39mld(target), ag__\u001b[38;5;241m.\u001b[39mld(enc_output), ag__\u001b[38;5;241m.\u001b[39mld(training), ag__\u001b[38;5;241m.\u001b[39mld(look_ahead_mask), ag__\u001b[38;5;241m.\u001b[39mld(padding_mask)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m final_output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfinal_layer, (ag__\u001b[38;5;241m.\u001b[39mld(dec_output),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/mambaforge/envs/iannwtf_final_project/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/mambaforge/envs/iannwtf_final_project/lib/python3.12/site-packages/keras/src/layers/layer.py:721\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(args):\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, KerasTensor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mis_tensor(\n\u001b[1;32m    719\u001b[0m             arg\n\u001b[1;32m    720\u001b[0m         ):\n\u001b[0;32m--> 721\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    722\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly input tensors may be passed as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    723\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional arguments. The following argument value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    724\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be passed as a keyword argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    725\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    726\u001b[0m             )\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# Caches info about `call()` signature, args, kwargs.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m call_spec \u001b[38;5;241m=\u001b[39m CallSpec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_signature, args, kwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/var/folders/p8/rh_91kl969g6rhp4ksqdmjhr0000gn/T/ipykernel_18354/2046511709.py\", line 41, in call  *\n        enc_output = self.encoder(input, training, padding_mask)\n    File \"/Users/christinearnoldt/mambaforge/envs/iannwtf_final_project/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/christinearnoldt/mambaforge/envs/iannwtf_final_project/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 721, in __call__\n        raise ValueError(\n\n    ValueError: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: True (of type <class 'bool'>)\n"
     ]
    }
   ],
   "source": [
    "#-----------Loop for different sequence lengths with custom training loop----------------#\n",
    "\n",
    "config_name= \"Transformer\"\n",
    "\n",
    "for length in SEQUENCE_LENGTH:\n",
    "    train_dataset = create_dataset_for_cum_sum_prediction(1024, length, 1, False)\n",
    "    val_dataset = create_dataset_for_cum_sum_prediction(512, length, 1, True)\n",
    "    \n",
    "    train_log_path = f\"logs/{config_name}/{length}/train\"\n",
    "    test_log_path = f\"logs/{config_name}/{length}/val\"\n",
    "    \n",
    "    # log writer for training metrics\n",
    "    train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "    \n",
    "    # log writer for validation metrics\n",
    "    test_summary_writer = tf.summary.create_file_writer(test_log_path)\n",
    "    \n",
    "    model = TransformerModel(num_layers=NUM_OF_LAYERS, dim=512, num_heads=8, dim_feedforward=2048, input_vocab_size=8500, target_vocab_size=8000)\n",
    "    train_losses, train_accuracies, val_losses, val_accuracies = training_loop(model, train_dataset, val_dataset, train_summary_writer, test_summary_writer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------Loop for different sequence lengths with compile and fit----------------#\n",
    "\n",
    "for length in SEQUENCE_LENGTH:\n",
    "    train_dataset = create_dataset_for_cum_sum_prediction(1024, length, 1, False)\n",
    "    val_dataset = create_dataset_for_cum_sum_prediction(512, length, 1, True)\n",
    "    \n",
    "    model = RNNModel(num_layers=NUM_OF_LAYERS, sequence_length=length, hidden_length=HIDDEN_LENGTH, cumsum=CUMSUM)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    loss = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer = optimizer, loss=loss)\n",
    "    \n",
    "    EXPERIMENT_NAME = \"LSTM_sum_prediction\"\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    logging_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"./logs/{EXPERIMENT_NAME}/{length}\")\n",
    "    \n",
    "    history = model.fit(train_dataset, \n",
    "                        validation_data=val_dataset,\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=[logging_callback],\n",
    "                        verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=\"logs/transformer_sum_prediction\" --port=6007"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iannwtf_final_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
